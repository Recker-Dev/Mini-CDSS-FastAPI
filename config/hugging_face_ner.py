from huggingface_hub import InferenceClient
import os

# from transformers import AutoTokenizer, AutoModelForTokenClassification
# import torch


# tokenizer = AutoTokenizer.from_pretrained("Clinical-AI-Apollo/Medical-NER")
# model = AutoModelForTokenClassification.from_pretrained("Clinical-AI-Apollo/Medical-NER")


# def process_ner_output(text: str, max_length: int = 512) -> list:
#     """
#     Process text using a pretrained NER model and tokenizer, returning meaningful predictions.
    
#     Parameters:
#         text (str): Input text to analyze.
#         model: Pretrained Hugging Face model for NER.
#         tokenizer: Corresponding tokenizer for the model.
#         max_length (int): Maximum sequence length for the tokenizer.

#     Returns:
#         list: A list of tuples in the format (token, label), excluding 'O' labels.
#     """
#     # Tokenize the text
#     encoding = tokenizer(
#         text,
#         truncation=True,
#         padding="max_length",
#         max_length=max_length,
#         return_tensors="pt"
#     )
    
#     # Get logits from the model
#     output = model(**encoding)
#     logits = output.logits
    
#     # Predict label indices
#     predicted_label_indices = torch.argmax(logits, dim=2)
    
#     # Map label indices to label names
#     label_map = model.config.id2label
#     predicted_labels = [label_map[idx.item()] for idx in predicted_label_indices[0]]
    
#     # Decode tokens
#     tokens = tokenizer.convert_ids_to_tokens(encoding["input_ids"][0])
    
#     # Combine tokens and labels
#     result = list(zip(tokens, predicted_labels))
    
#     # Filter out non-entity tokens ('O' labels)
#     filtered_result = [
#         (token.lstrip("▁"), label)  # Remove leading underscores from tokens
#         for token, label in result if label != "O"
#     ]

#     unique_tags = []

#     for entry in predicted_labels:
#         if entry[0]=="B" and entry not in unique_tags:
#             unique_tags.append(entry[2:])
    
#     return filtered_result,unique_tags

# def generate_clean_ner_report(tagged_tokens, unique_tags):
#     """
#     Generate a clean NER report based on tagged tokens and unique tags.
    
#     Parameters:
#         tagged_tokens (list): List of tuples with tokens and labels.
#         unique_tags (list): List of unique entity tags.

#     Returns:
#         dict: A report in the format {tag: [relevant details]}.
#     """
#     # Initialize report with all unique tags except unwanted ones
#     unwanted_tokens = {'[CLS]', '[SEP]'}
#     report = {tag: [] for tag in unique_tags if tag != "SEVERITY"}

#     current_entity = []
#     current_label = None

#     for token, tag in tagged_tokens:
#         # Remove underscores and filter unwanted tokens
#         token = token.replace('▁', '')
#         if token in unwanted_tokens:
#             continue

#         if tag.startswith("B-"):
#             # Save the previous entity if it exists
#             if current_entity:
#                 report[current_label].append(" ".join(current_entity))
#             # Start a new entity
#             current_entity = [token]
#             current_label = tag[2:]  # Remove the "B-" prefix
#         elif tag.startswith("I-") and current_label == tag[2:]:
#             # Continue the current entity if the label matches
#             current_entity.append(token)
#         else:
#             # Save the previous entity and reset if the tag doesn't match
#             if current_entity:
#                 report[current_label].append(" ".join(current_entity))
#             current_entity = []
#             current_label = None

#     # Add the last entity if any
#     if current_entity:
#         report[current_label].append(" ".join(current_entity))

#     return report


def ner_extractor(input_text):
    client = InferenceClient(
	provider="hf-inference",
	api_key=os.environ["HF_TOKEN"]
    )

    result = client.token_classification(
        model="blaze999/Medical-NER",
        text=input_text
        
    )
    
    entity_groups = set()

    for entry in result:
        if entry.score>0.8:
            entity_groups.add(entry.entity_group)
        
    
    entity_dict = {key: [] for key in entity_groups}

    for entry in result:
        if entry.score>0.8:
            entity_dict[entry.entity_group].append(entry.word)

    return entity_dict

